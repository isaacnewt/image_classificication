{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecf01d1",
   "metadata": {},
   "source": [
    "# The objective of this exercise is to create an image classification task for garments in an ecommerce store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import keras\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        brightness_range=[0.2,1.2]) # brightness\n",
    "\n",
    "\n",
    "# Home directory\n",
    "home_path = r'./train_LbELtWX'\n",
    "\n",
    "# Original df\n",
    "df = pd.read_csv(home_path + r'/train.csv')\n",
    "\n",
    "df['id'] = df['id'].astype('str') # requires target in string\n",
    "df['label'] = df['label'].astype('str')\n",
    "\n",
    "train_generator_df = datagen.flow_from_dataframe(dataframe=df, \n",
    "                                              directory=home_path+'/train/',\n",
    "                                              x_col=\"id\", \n",
    "                                              y_col=\"label\", \n",
    "                                              class_mode=\"categorical\", \n",
    "                                              target_size=(200, 200), \n",
    "                                              batch_size=1,\n",
    "                                              rescale=1.0/255,\n",
    "                                              seed=2020)\n",
    "# plotting images\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    # convert to unsigned integers for plotting\n",
    "    image = next(train_generator_df)[0].astype('uint8')\n",
    "\n",
    "    # changing size from (1, 200, 200, 3) to (200, 200, 3) for plotting the image\n",
    "    image = np.squeeze(image)\n",
    "\n",
    "    # plot raw pixel data\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "def process_image(raw_image):\n",
    "    raw_image = tf.reshape(raw_image, [-1])\n",
    "    img_rgb = tf.io.decode_jpeg(raw_image, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    resized_img = tf.image.resize_with_pad(\n",
    "        img,\n",
    "        target_height=300,\n",
    "        target_width=300\n",
    "        )\n",
    "    img_grayscale = tf.image.rgb_to_grayscale(resized_img)\n",
    "    return tf.reshape(img_grayscale, [-1, 300, 300, 1])\n",
    "\n",
    "# Images and Labels\n",
    "X = df.loc[:,'id']\n",
    "y = df.loc[:,'label']\n",
    "\n",
    "\n",
    "# Train-Test splitfor train and validation images\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, test_size = 0.3, random_state = 27, stratify=y)\n",
    "\n",
    "# Train df\n",
    "df_train = pd.DataFrame(columns=['id','label'])\n",
    "df_train['id'] = train_x\n",
    "df_train['label'] = train_y\n",
    "\n",
    "# Validation df\n",
    "df_test = pd.DataFrame(columns=['id','label'])\n",
    "df_test['id'] = val_x\n",
    "df_test['label'] = val_y\n",
    "\n",
    "# Reset index\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Images\n",
    "train_images = df_train.loc[:,'id']\n",
    "train_labels = df_train.loc[:,'label']\n",
    "\n",
    "test_images = df_test.loc[:,'id']\n",
    "test_labels = df_test.loc[:,'label']\n",
    "\n",
    "# Train images\n",
    "x_train = []\n",
    "for i in train_images:\n",
    "    image = home_path+'/train/'+i\n",
    "    img = cv2.imread(image)\n",
    "    x_train.append(img)\n",
    "\n",
    "# Train labels\n",
    "y_train=keras.utils.to_categorical(train_labels)\n",
    "\n",
    "# Test images\n",
    "x_test = []\n",
    "for i in test_images:\n",
    "    image = home_path+'/train/'+i\n",
    "    img = cv2.imread(image)\n",
    "    x_test.append(img)\n",
    "\n",
    "# Test labels\n",
    "y_test=keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Normalize images\n",
    "x_train = np.array(x_train, dtype=\"float\") / 255.0\n",
    "x_test = np.array(x_test, dtype=\"float\") / 255.0\n",
    "\n",
    "from keras.backend import image_data_format\n",
    "\n",
    "if image_data_format() == 'channel_first':\n",
    "    train.reshape(train.shape[0],1,x,x) # where x is image format such as 32\n",
    "    input_shape=(1,x,x)\n",
    "else:\n",
    "    train.reshape(train.shape[0],x,x,1)\n",
    "    input_shape=(x,x,1)\n",
    "    \n",
    "\n",
    "\n",
    "# Model architechture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(200, 200, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.24))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(200, 200, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(26, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_datagen.flow(training_images, training_labels, batch_size=32),\n",
    "                              steps_per_epoch=len(training_images) / 32,\n",
    "                              epochs=15,\n",
    "                              validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),\n",
    "                              validation_steps=len(testing_images) / 32)\n",
    "\n",
    "model.evaluate(testing_images, testing_labels)\n",
    "\n",
    "# Compile\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "optim = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n",
    "# Fit\n",
    "history = model.fit(x_train,y_train,\n",
    "                    epochs=25,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n",
    "from keras.backend import image_data_format\n",
    "\n",
    "if image_data_format() == 'channel_first':\n",
    "    train.reshape(train.shape[0],1,x,x) # where x is image format such as 32\n",
    "    input_shape=(1,x,x)\n",
    "else:\n",
    "    train.reshape(train.shape[0],x,x,1)\n",
    "    input_shape=(x,x,1)\n",
    "    \n",
    "# Augmenting on the fly with fit_generator()\n",
    "\n",
    "# or use iterator from .flow_from_datafram()\n",
    "model.fit_generator(train_generator_df, \n",
    "                    epochs=epochs,  # one forward/backward pass of training data\n",
    "                    steps_per_epoch=x_train.shape[0]//batch_size,  # number of images comprising of one epoch\n",
    "                    validation_data=(x_test, y_test),  # Or validation_data=valid_generator\n",
    "                    validation_steps=x_test.shape[0]//batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
